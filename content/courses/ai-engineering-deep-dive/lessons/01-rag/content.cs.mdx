# Retrieval-Augmented Generation (RAG) ğŸ”

<Callout type="info">
**Mise:** Budujte AI systÃ©my, kterÃ© znajÃ­ VAÅ E data - nauÄte se pÅ™ekonat knowledge cutoff a halucinace ukotvenÃ­m AI v externÃ­ch znalostech.

â³ **ÄŒas ÄtenÃ­:** 40 min | ğŸ§ª **[3] Laby souÄÃ¡stÃ­**
</Callout>

<VideoSwitcher alternatives={[{"id":"_HQ2H_0Ayy0","title":"RAG Explained For Beginners (KodeKloud)"},{"id":"sVcwVQRHIc8","title":"Learn RAG From Scratch - Python Tutorial (freeCodeCamp)"},{"id":"gl1r1XV0SLw","title":"What is a Vector Database? (IBM)"},{"id":"dN0lsF2cvm4","title":"Vector Databases Simply Explained (AssemblyAI)"}]} />

**ProblÃ©m s LLM: Jsou zamrzlÃ© v Äase.**

ChatGPT nevÃ­, co se stalo vÄera. Claude neumÃ­ ÄÃ­st internÃ­ dokumenty vaÅ¡Ã­ firmy. KaÅ¾dÃ½ LLM mÃ¡ **knowledge cutoff** - ÄasovÃ½ bod, kde jeho trÃ©ninkovÃ¡ data konÄÃ­. Po tom? HÃ¡dÃ¡.

A kdyÅ¾ hÃ¡dÃ¡, **halucinuje** - sebevÄ›domÄ› vymÃ½Å¡lÃ­ fakta, kterÃ¡ znÄ›jÃ­ vÄ›rohodnÄ›, ale jsou ÃºplnÄ› Å¡patnÄ›.

**RAG Å™eÅ¡Ã­ oba problÃ©my.** MÃ­sto spolÃ©hÃ¡nÃ­ vÃ½hradnÄ› na to, co si model "pamatuje", mu dÃ¡me pÅ™Ã­stup k externÃ­m znalostem *v dobÄ› dotazu*.

---

## ProÄ na RAG zÃ¡leÅ¾Ã­

<ConceptCard title="ProblÃ©m znalostÃ­" icon="ğŸ§ ">

LLM majÃ­ dvÄ› fundamentÃ¡lnÃ­ omezenÃ­:

1. **Knowledge Cutoff**: TrÃ©nink skonÄil v urÄitÃ©m datu (napÅ™. duben 2024)
2. **Å½Ã¡dnÃ½ pÅ™Ã­stup k privÃ¡tnÃ­m datÅ¯m**: NeumÃ­ ÄÃ­st vaÅ¡e dokumenty, databÃ¡ze nebo internÃ­ systÃ©my

**RAG (Retrieval-Augmented Generation)** to Å™eÅ¡Ã­ tÃ­m, Å¾e:
- ZÃ­skÃ¡ relevantnÃ­ dokumenty z vaÅ¡Ã­ znalostnÃ­ bÃ¡ze
- VloÅ¾Ã­ je do promptu jako kontext
- NechÃ¡ LLM generovat odpovÄ›di zaloÅ¾enÃ© na reÃ¡lnÃ½ch datech

</ConceptCard>

### Slib RAG

| ProblÃ©m | Bez RAG | S RAG |
|---------|---------|-------|
| "JakÃ© jsou naÅ¡e Q4 trÅ¾by?" | VymyÅ¡lenÃ© ÄÃ­slo | PÅ™esnÃ© z vaÅ¡ich reportÅ¯ |
| "Co se stalo vÄera?" | "NemÃ¡m tu informaci" | Real-time naÄtenÃ­ novinek |
| "FiremnÃ­ politika ohlednÄ› X?" | ObecnÃ½ odhad | VÃ¡Å¡ skuteÄnÃ½ dokument |

---

## RAG Pipeline

KaÅ¾dÃ½ RAG systÃ©m nÃ¡sleduje stejnÃ½ tÅ™Ã­fÃ¡zovÃ½ pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  1. INDEX (Offline - JednorÃ¡zovÄ›)                       â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ Dokumentyâ”‚ -> â”‚ RozdÄ›l   â”‚ -> â”‚ Embeduj &    â”‚   â”‚
â”‚     â”‚          â”‚    â”‚ (Chunk)  â”‚    â”‚ UloÅ¾ do DB   â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â”‚  2. RETRIEVE (Online - PÅ™i dotazu)                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ Dotaz    â”‚ -> â”‚ Embeduj  â”‚ -> â”‚ VektorovÃ¡    â”‚   â”‚
â”‚     â”‚ uÅ¾ivateleâ”‚    â”‚ dotaz    â”‚    â”‚ podobnost    â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â”‚  3. GENERATE (Online - PÅ™i dotazu)                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ ZÃ­skanÃ©  â”‚ -> â”‚ Sestav   â”‚ -> â”‚ LLM          â”‚   â”‚
â”‚     â”‚ chunky   â”‚    â”‚ prompt   â”‚    â”‚ odpovÄ›Ä      â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

PojÄme si rozebrat kaÅ¾dou fÃ¡zi:

<Diagram type="rag-architecture" />

---

## FÃ¡ze 1: IndexovÃ¡nÃ­

NeÅ¾ RAG mÅ¯Å¾e fungovat, musÃ­te pÅ™ipravit svou znalostnÃ­ bÃ¡zi.

### Krok 1: NaÄtenÃ­ dokumentÅ¯

NaÄtÄ›te dokumenty z rÅ¯znÃ½ch zdrojÅ¯:
- PDF, Word dokumenty, textovÃ© soubory
- Web strÃ¡nky, API
- DatabÃ¡ze, tabulky
- Slack zprÃ¡vy, emaily

### Krok 2: Chunking (DÄ›lenÃ­)

**KritickÃ© rozhodnutÃ­:** LLM majÃ­ limity kontextu. NemÅ¯Å¾ete nacpat celÃ© knihy do promptu. MusÃ­te rozdÄ›lit dokumenty na menÅ¡Ã­ **chunky**.

| Strategie chunkingu | NejlepÅ¡Ã­ pro | TypickÃ¡ velikost |
|---------------------|--------------|------------------|
| **FixnÃ­ velikost** | JednoduchÃ© dokumenty | 500-1000 tokenÅ¯ |
| **SÃ©mantickÃ½** | TechnickÃ© dokumenty | Variuje dle vÃ½znamu |
| **Po vÄ›tÃ¡ch** | Q&A datasety | 1-5 vÄ›t |
| **Po odstavcÃ­ch** | ÄŒlÃ¡nky, blogy | PÅ™irozenÃ© zlomy |

<Callout type="warning">
**Trade-off velikosti chunku:**
- **PÅ™Ã­liÅ¡ malÃ©:** ZtrÃ¡cÃ­ kontext, zÃ­skÃ¡vÃ¡ irelevantnÃ­ fragmenty
- **PÅ™Ã­liÅ¡ velkÃ©:** PlÃ½tvÃ¡ kontextovÃ½m oknem, Å™edÃ­ relevantnÃ­ info
- **Sweet spot:** 200-500 tokenÅ¯ s 10-20% pÅ™ekryvem
</Callout>

### Krok 3: Embedding

Transformujte textovÃ© chunky na **vektory** (pole ÄÃ­sel), kterÃ© zachycujÃ­ sÃ©mantickÃ½ vÃ½znam.

```python
# PÅ™Ã­klad: VytvoÅ™enÃ­ embeddingÅ¯
from openai import OpenAI

client = OpenAI()

text = "RAG kombinuje retrieval s generovÃ¡nÃ­m"
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=text
)

# VÃ½sledek: [0.0023, -0.0152, 0.0341, ...] (1536 dimenzÃ­)
embedding = response.data[0].embedding
```

**PopulÃ¡rnÃ­ Embedding modely:**

| Model | Dimenze | Poskytovatel | NejlepÅ¡Ã­ pro |
|-------|---------|--------------|--------------|
| text-embedding-3-small | 1536 | OpenAI | NÃ¡kladovÄ› efektivnÃ­ |
| text-embedding-3-large | 3072 | OpenAI | NejvyÅ¡Å¡Ã­ kvalita |
| all-MiniLM-L6-v2 | 384 | HuggingFace | Zdarma, rychlÃ½ |
| voyage-2 | 1024 | Voyage AI | KÃ³d & prÃ¡vo |

### Krok 4: UloÅ¾enÃ­ do vektorovÃ© databÃ¡ze

UloÅ¾te embeddingy do specializovanÃ© databÃ¡ze podporujÃ­cÃ­ vyhledÃ¡vÃ¡nÃ­ podobnosti.

---

## ğŸ”¬ Lab 1: VytvoÅ™te svÃ© prvnÃ­ embeddingy

PojÄme si vyzkouÅ¡et, jak embeddingy zachycujÃ­ sÃ©mantickÃ½ vÃ½znam!

**CÃ­l:** Pochopte, jak se podobnÃ© koncepty shlukujÃ­ ve vektorovÃ©m prostoru.

**Prompt:**
ZkopÃ­rujte do ChatGPT nebo Claude:

```text
Jsi asistent pro vizualizaci embeddingÅ¯. DÃ¡m ti vÄ›ty a ty odhadneÅ¡
jejich sÃ©mantickou podobnost na Å¡kÃ¡le 0-100.

OhodnoÅ¥ podobnost mezi kaÅ¾dÃ½m pÃ¡rem:

VÄ›ty:
A: "KoÄka sedÄ›la na rohoÅ¾ce"
B: "KoÄkovitÃ¡ Å¡elma odpoÄÃ­vala na koberci"
C: "Psi jsou vÄ›rnÃ­ mazlÃ­Äci"
D: "AkciovÃ½ trh vÄera zkolaboval"

Porovnej:
1. A vs B: ?
2. A vs C: ?
3. A vs D: ?
4. B vs C: ?
```

**OÄekÃ¡vanÃ½ vÃ½stup:**
```
1. A vs B: 95 (tÃ©mÄ›Å™ identickÃ½ vÃ½znam, jinÃ¡ slova)
2. A vs C: 40 (oboje o mazlÃ­ÄcÃ­ch, ale jinÃ¡ zvÃ­Å™ata/akce)
3. A vs D: 5 (ÃºplnÄ› nesouvisejÃ­cÃ­ tÃ©mata)
4. B vs C: 35 (oboje o zvÃ­Å™atech, ale jinÃ½ kontext)
```

**ğŸ’¡ Aha moment:** "PÅ™esnÄ› tohle embedding modely dÄ›lajÃ­ matematicky! PÅ™evÃ¡dÄ›jÃ­ vÄ›ty na vektory, kde podobnÃ½ vÃ½znam = blÃ­zkÃ© vektory."

<LabComplete labId="lab-rag-1" />

---

## FÃ¡ze 2: Retrieval (ZÃ­skÃ¡vÃ¡nÃ­)

KdyÅ¾ uÅ¾ivatel poloÅ¾Ã­ otÃ¡zku, potÅ™ebujeme najÃ­t nejrelevantnÄ›jÅ¡Ã­ chunky.

### VektorovÃ© vyhledÃ¡vÃ¡nÃ­ podobnosti

1. **Embeduj dotaz** pomocÃ­ stejnÃ©ho modelu
2. **VypoÄÃ­tej vzdÃ¡lenost** mezi vektorem dotazu a vÅ¡emi uloÅ¾enÃ½mi vektory
3. **VraÅ¥ top-K** nejpodobnÄ›jÅ¡Ã­ch chunkÅ¯

```python
# KonceptuÃ¡lnÃ­ pÅ™Ã­klad
dotaz = "JakÃ¡ je naÅ¡e politika vrÃ¡cenÃ­ penÄ›z?"
dotaz_embedding = embed(dotaz)

# Najdi podobnÃ© chunky (zjednoduÅ¡eno)
vysledky = vector_db.similarity_search(
    dotaz_embedding,
    k=5  # VraÅ¥ 5 nejrelevantnÄ›jÅ¡Ã­ch chunkÅ¯
)
```

### Metriky vzdÃ¡lenosti

| Metrika | Vzorec | Kdy pouÅ¾Ã­t |
|---------|--------|------------|
| **KosinovÃ¡ podobnost** | cos(Î¸) | NejbÄ›Å¾nÄ›jÅ¡Ã­, normalizovanÃ¡ |
| **EuklidovskÃ¡ vzdÃ¡lenost** | âˆšÎ£(a-b)Â² | SurovÃ¡ vzdÃ¡lenost |
| **SkalÃ¡rnÃ­ souÄin** | Î£(aÃ—b) | KdyÅ¾ zÃ¡leÅ¾Ã­ na magnitudÄ› |

<Callout type="tip">
**Pro tip:** KosinovÃ¡ podobnost je tÃ©mÄ›Å™ vÅ¾dy sprÃ¡vnÃ¡ volba pro textovÃ© embeddingy. Ignoruje magnitudu vektoru a zamÄ›Å™uje se na smÄ›r (vÃ½znam).
</Callout>

---

## PorovnÃ¡nÃ­ vektorovÃ½ch databÃ¡zÃ­

PotÅ™ebujete specializovanou databÃ¡zi pro efektivnÃ­ uklÃ¡dÃ¡nÃ­ a vyhledÃ¡vÃ¡nÃ­ milionÅ¯ vektorÅ¯.

| DatabÃ¡ze | Typ | NejlepÅ¡Ã­ pro | Cena |
|----------|-----|--------------|------|
| **Pinecone** | Managed | Produkce, enterprise | Pay-per-use |
| **Chroma** | Open-source | LokÃ¡lnÃ­ vÃ½voj, prototypy | Zdarma |
| **Weaviate** | Hybrid | GraphQL fanouÅ¡ci, hybridnÃ­ search | Zdarma + managed |
| **Qdrant** | Open-source | Self-hosted, Rust vÃ½kon | Zdarma |
| **pgvector** | PostgreSQL ext | ExistujÃ­cÃ­ Postgres uÅ¾ivatelÃ© | Zdarma |

### RychlÃ© porovnÃ¡nÃ­

```
Pinecone:  ğŸ¢ Enterprise   | âš¡ NejrychlejÅ¡Ã­ | ğŸ’° $$
Chroma:    ğŸ§ª PrototypovÃ¡nÃ­| ğŸ Pythonic    | ğŸ’° Zdarma
Weaviate:  ğŸ”— Hybrid       | ğŸ“Š GraphQL     | ğŸ’° Zdarma/$
Qdrant:    ğŸ¦€ VÃ½kon        | ğŸ”§ Self-host   | ğŸ’° Zdarma
```

---

## FÃ¡ze 3: GenerovÃ¡nÃ­

NynÃ­ zkombinujeme zÃ­skanÃ½ kontext s otÃ¡zkou uÅ¾ivatele.

### RAG Prompt Å¡ablona

```text
Jsi nÃ¡pomocnÃ½ asistent. OdpovÄ›z na otÃ¡zku POUZE na zÃ¡kladÄ›
nÃ¡sledujÃ­cÃ­ho kontextu. Pokud kontext neobsahuje odpovÄ›Ä, Å™ekni
"NemÃ¡m dostatek informacÃ­ pro odpovÄ›Ä na tuto otÃ¡zku."

Kontext:
{ziskane_chunky}

OtÃ¡zka: {uzivatelska_otazka}

OdpovÄ›Ä:
```

<Callout type="warning">
**UkotvenÃ­ je kritickÃ©:**
VÅ¾dy instrukuj model, aby pouÅ¾Ã­val POUZE poskytnutÃ½ kontext. Jinak mÅ¯Å¾e mÃ­chat zÃ­skanÃ¡ fakta s halucinovanÃ½mi.
</Callout>

---

## ğŸ”¬ Lab 2: Sestavte RAG prompt

PojÄme zkonstruovat sprÃ¡vnÃ½ RAG prompt a podÃ­vat se, jak kontext mÄ›nÃ­ odpovÄ›Ä!

**CÃ­l:** ZaÅ¾ijte, jak zÃ­skanÃ½ kontext transformuje odpovÄ›di AI.

**ÄŒÃ¡st 1 - Bez kontextu:**
```text
JakÃ¡ je maximÃ¡lnÃ­ lhÅ¯ta pro vrÃ¡cenÃ­ penÄ›z za software u TechCorp?
```
(AI bude halucinovat nebo Å™ekne, Å¾e nevÃ­)

**ÄŒÃ¡st 2 - S RAG kontextem:**
```text
Jsi nÃ¡pomocnÃ½ zÃ¡kaznickÃ½ asistent pro TechCorp. OdpovÃ­dej POUZE
na zÃ¡kladÄ› nÃ¡sledujÃ­cÃ­ch dokumentÅ¯. Pokud odpovÄ›Ä nenajdeÅ¡,
Å™ekni "Tuto informaci nemÃ¡m v naÅ¡ich dokumentech."

KONTEXT:
---
Dokument: TechCorp Refund Policy (AktualizovÃ¡no Leden 2024)
Sekce 3.2: NÃ¡kupy softwaru
- DigitÃ¡lnÃ­ software: 14dennÃ­ lhÅ¯ta pro vrÃ¡cenÃ­ od data nÃ¡kupu
- Enterprise licence: 30dennÃ­ zkuÅ¡ebnÃ­ obdobÃ­ s plnÃ½m vrÃ¡cenÃ­m
- PÅ™edplatnÃ©: PomÄ›rnÃ© vrÃ¡cenÃ­ pro roÄnÃ­ plÃ¡ny, bez vrÃ¡cenÃ­ u mÄ›sÃ­ÄnÃ­ch
- VÃ½jimky: AktivovanÃ© licenÄnÃ­ klÃ­Äe nelze vrÃ¡tit
---

OtÃ¡zka: JakÃ¡ je maximÃ¡lnÃ­ lhÅ¯ta pro vrÃ¡cenÃ­ penÄ›z za software u TechCorp?
```

**OÄekÃ¡vanÃ½ vÃ½stup:**
```
Na zÃ¡kladÄ› refund policy TechCorp zÃ¡visÃ­ maximÃ¡lnÃ­ lhÅ¯ta pro vrÃ¡cenÃ­
na typu nÃ¡kupu softwaru:

- DigitÃ¡lnÃ­ software: 14 dnÃ­ od data nÃ¡kupu
- Enterprise licence: 30 dnÃ­ (zkuÅ¡ebnÃ­ obdobÃ­)
- PÅ™edplatnÃ©: PomÄ›rnÃ© pro roÄnÃ­ plÃ¡ny

NejdelÅ¡Ã­ lhÅ¯ta pro vrÃ¡cenÃ­ je 30 dnÃ­ pro enterprise licence.

PoznÃ¡mka: AktivovanÃ© licenÄnÃ­ klÃ­Äe nelze vrÃ¡tit bez ohledu na ÄasovÃ© obdobÃ­.
```

**ğŸ’¡ Aha moment:** "AI pÅ™eÅ¡la od hÃ¡dÃ¡nÃ­ k pÅ™esnÃ½m, zdrojovanÃ½m odpovÄ›dÃ­m. To je sÃ­la RAG - ukotvenÃ­ AI v reÃ¡lnÃ½ch datech!"

<LabComplete labId="lab-rag-2" />

---

## PokroÄilÃ© RAG techniky

ZÃ¡kladnÃ­ RAG je jen zaÄÃ¡tek. ProdukÄnÃ­ systÃ©my pouÅ¾Ã­vajÃ­ pokroÄilÃ© techniky:

### 1. HybridnÃ­ vyhledÃ¡vÃ¡nÃ­

Kombinujte vektorovÃ© vyhledÃ¡vÃ¡nÃ­ s keyword searchem (BM25) pro lepÅ¡Ã­ vÃ½sledky.

```
Dotaz: "ISO 27001 compliance"

Pouze vektor: Najde dokumenty o "bezpeÄnostnÃ­ch standardech" (sÃ©mantickÃ©)
Pouze keyword: Najde dokumenty obsahujÃ­cÃ­ "ISO 27001" (pÅ™esnÃ©)
Hybrid: Najde oboje + optimÃ¡lnÄ› seÅ™adÃ­
```

### 2. Re-Ranking

Po poÄÃ¡teÄnÃ­m retrievalu pouÅ¾ijte cross-encoder pro pÅ™ehodnocenÃ­ relevance vÃ½sledkÅ¯.

### 3. Transformace dotazu

ZlepÅ¡ete retrieval transformacÃ­ uÅ¾ivatelskÃ©ho dotazu:
- **HyDE:** Vygenerujte hypotetickou odpovÄ›Ä, pak hledejte podobnÃ© dokumenty
- **Multi-Query:** Vygenerujte vÃ­ce variant otÃ¡zky
- **Step-Back:** Zeptejte se nejdÅ™Ã­v obecnÄ›jÅ¡Ã­ otÃ¡zky

### 4. KontextovÃ¡ komprese

Sumarizujte nebo filtrujte zÃ­skanÃ© chunky pÅ™ed pÅ™edÃ¡nÃ­m LLM.

---

## BÄ›Å¾nÃ© RAG problÃ©my

| ProblÃ©m | Symptom | Å˜eÅ¡enÃ­ |
|---------|---------|--------|
| **PÅ™Ã­liÅ¡ agresivnÃ­ chunking** | ZÃ­skanÃ© fragmenty jsou bezvÃ½znamnÃ© | ZvÄ›tÅ¡it chunk size, pÅ™idat overlap |
| **Å patnÃ½ embedding model** | IrelevantnÃ­ vÃ½sledky retrievalu | Sladit model s domÃ©nou (kÃ³d, prÃ¡vo, atd.) |
| **K pÅ™Ã­liÅ¡ nÃ­zkÃ©** | ChybÃ­ relevantnÃ­ kontext | ZvÃ½Å¡it K, pouÅ¾Ã­t re-ranking |
| **K pÅ™Ã­liÅ¡ vysokÃ©** | Å˜edÃ­ signÃ¡l Å¡umem | SnÃ­Å¾it K, pouÅ¾Ã­t kompresi |
| **ChybÃ­ grounding instrukce** | LLM mÃ­chÃ¡ fakta s halucinacemi | ExplicitnÃ­ "POUZE pouÅ¾ij kontext" prompt |

---

## ğŸ”¬ Lab 3: Debugujte RAG selhÃ¡nÃ­

PojÄme diagnostikovat, proÄ RAG systÃ©m mÅ¯Å¾e selhÃ¡vat, a opravit to!

**CÃ­l:** NauÄte se troubleshootovat bÄ›Å¾nÃ© RAG problÃ©my.

**ScÃ©nÃ¡Å™:**
VÃ¡Å¡ RAG systÃ©m vracÃ­ Å¡patnÃ© odpovÄ›di na technickÃ© otÃ¡zky.

**Debug prompt:**
```text
Jsi RAG system debugger. Na zÃ¡kladÄ› tohoto scÃ©nÃ¡Å™e identifikuj problÃ©m
a navrhni opravu:

KONFIGURACE SYSTÃ‰MU:
- Embedding model: text-embedding-3-small
- Chunk size: 100 tokenÅ¯ (bez overlapu)
- Top-K: 2
- Dokumenty: TechnickÃ¡ API dokumentace (500 stran)

DOTAZ UÅ½IVATELE: "Jak se autentifikuji pomocÃ­ OAuth 2.0?"

ZÃSKANÃ‰ CHUNKY:
1. "OAuth je protokol pro..." (obecnÃ½ Ãºvod, strana 1)
2. "Pro autentifikaci pouÅ¾ijte login endpoint..." (nesouvisejÃ­cÃ­ endpoint)

SKUTEÄŒNÃ LOKACE ODPOVÄšDI: Strany 45-48, "OAuth 2.0 Implementation Guide"

ProÄ retrieval selhal? Co bys zmÄ›nil?
```

**OÄekÃ¡vanÃ¡ analÃ½za:**
```
IDENTIFIKOVANÃ‰ PROBLÃ‰MY:

1. Chunk size pÅ™Ã­liÅ¡ malÃ½ (100 tokenÅ¯)
   - TechnickÃ© dokumenty potÅ™ebujÃ­ vÄ›tÅ¡Ã­ kontext
   - Oprava: ZvÃ½Å¡it na 400-500 tokenÅ¯ s 50 token overlapem

2. Top-K pÅ™Ã­liÅ¡ nÃ­zkÃ© (2)
   - Pro 500strÃ¡nkovÃ½ dokument jsou 2 chunky nedostateÄnÃ©
   - Oprava: ZvÃ½Å¡it na 5-10, pak pouÅ¾Ã­t re-ranking

3. ChybÃ­ hybridnÃ­ vyhledÃ¡vÃ¡nÃ­
   - "OAuth 2.0" je specifickÃ½ termÃ­n, kterÃ½ benefituje z keyword matchingu
   - Oprava: Povolit BM25 + vector hybrid search

4. MoÅ¾nÃ½ embedding mismatch
   - ObecnÃ½ embedding model pro technickÃ© dokumenty
   - ZvÃ¡Å¾it: SpecializovanÃ½ code/technickÃ½ embedding model
```

**ğŸ’¡ Aha moment:** "RAG selhÃ¡nÃ­ jsou obvykle systematickÃ¡, ne nÃ¡hodnÃ¡. Debug proces: Zkontroluj chunky â†’ Zkontroluj retrieval â†’ Zkontroluj prompt â†’ Zkontroluj model."

<LabComplete labId="lab-rag-3" />

---

## RAG implementaÄnÃ­ checklist

PÅ™ed nasazenÃ­m RAG do produkce:

```
â–¡ Data Pipeline
  â–¡ Document loader zvlÃ¡dÃ¡ vÅ¡echny vaÅ¡e typy souborÅ¯
  â–¡ Chunking strategie otestovÃ¡na se vzorovÃ½mi dotazy
  â–¡ Embedding model vhodnÃ½ pro domÃ©nu

â–¡ Retrieval
  â–¡ VektorovÃ¡ databÃ¡ze vybrÃ¡na a nakonfigurovÃ¡na
  â–¡ Top-K vyladÄ›no pro vÃ¡Å¡ use case
  â–¡ HybridnÃ­ search povoleno pokud potÅ™eba

â–¡ GenerovÃ¡nÃ­
  â–¡ Grounding instrukce v system promptu
  â–¡ Citace zdrojÅ¯ v odpovÄ›dÃ­ch
  â–¡ Fallback pro "Å¾Ã¡dnÃ½ relevantnÃ­ kontext"

â–¡ Evaluace
  â–¡ PÅ™esnost retrievalu mÄ›Å™ena (Recall@K)
  â–¡ End-to-end kvalita odpovÄ›dÃ­ testovÃ¡na
  â–¡ Detekce halucinacÃ­ zavedena
```

---

<ConceptCard title="Holokron: RAG ZÃ¡klady" icon="ğŸ’">

### ğŸ”‘ KlÃ­ÄovÃ© poznatky

* **Co to je:** Retrieval-Augmented Generation - dÃ¡vÃ¡nÃ­ LLM pÅ™Ã­stupu k externÃ­m znalostem v dobÄ› dotazu
* **ProÄ zÃ¡leÅ¾Ã­:** Å˜eÅ¡Ã­ problÃ©my knowledge cutoff a halucinacÃ­
* **Pipeline:** Index (chunk + embed) â†’ Retrieve (similarity search) â†’ Generate (ukotvenÃ¡ odpovÄ›Ä)
* **KlÃ­ÄovÃ¡ rozhodnutÃ­:** Chunk size, embedding model, vektorovÃ¡ databÃ¡ze, top-K
* **PokroÄilÃ© techniky:** HybridnÃ­ search, re-ranking, transformace dotazu
* **ProdukÄnÃ­ checklist:** Data pipeline + tuning retrievalu + grounding prompty + evaluace

**DalÅ¡Ã­ kroky:** NauÄte se o Agent Frameworks, kterÃ© orchestrujÃ­ RAG s dalÅ¡Ã­mi nÃ¡stroji!

</ConceptCard>
