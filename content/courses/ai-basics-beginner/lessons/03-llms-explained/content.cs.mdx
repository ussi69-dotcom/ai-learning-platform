# Mysl stroje: LLM ğŸ¤–

<Callout type="info">
**CÃ­l mise:** OtevÅ™Ã­t mozek ChatGPT a podÃ­vat se, jak myslÃ­ (v ÄÃ­slech).
â³ **ÄŒas ÄtenÃ­:** 20 min | ğŸ§ª **2 LaboratoÅ™e**
</Callout>

VÃ­tej, Padawane. NauÄil ses, *jak* se AI uÄÃ­. NynÃ­ je Äas setkat se se samotnÃ½m droidem.
Å˜Ã­kÃ¡me jim **VelkÃ© jazykovÃ© modely (LLM)**.

ChatGPT, Claude, Geminiâ€”vÅ¡echno to jsou LLM. NezasvÄ›cenÃ½m pÅ™ipadajÃ­ jako magie. Pro Jediho jsou to jednoduÅ¡e... **PrediktivnÃ­ motory**.

---

## ğŸ”® 1. Hra na pÅ™edpovÃ­dÃ¡nÃ­

PÅ™edstav si, Å¾e C-3PO pÅ™eklÃ¡dÃ¡ prastarÃ½ sithskÃ½ dialekt. NecÃ­tÃ­ v tÄ›ch slovech hnÄ›v. VypoÄÃ­tÃ¡vÃ¡ **pravdÄ›podobnost**, kterÃ© slovo obvykle nÃ¡sleduje po tom pÅ™edchozÃ­m.

LLM je pÅ™esnÄ› tohle. Je to stroj vycviÄenÃ½ na celÃ©m internetu (Archivy JediÅ¯), aby hrÃ¡l jednu jednoduchou hru: **"UhÃ¡dni dalÅ¡Ã­ token."**

<Diagram type="llm-next-token" />

<ConceptCard title="Predikce dalÅ¡Ã­ho tokenu" icon="ğŸ”®" jediQuote="SoustÅ™eÄ se na okamÅ¾ik. Co pÅ™ijde dÃ¡l?">
*   **VstupnÃ­ kontext:** "Obloha je..."
*   **VÃ½poÄet:** ModrÃ¡ (90 %), Å edÃ¡ (5 %), ZelenÃ¡ (1 %).
*   **Akce:** AI hodÃ­ kostkou na zÃ¡kladÄ› tÄ›chto pravdÄ›podobnostÃ­ a vybere "ModrÃ¡".
</ConceptCard>

---

---

## ğŸ—ï¸ 2. Motor: Pozornost je vÅ¡e, co potÅ™ebujeÅ¡

PÅ™ed rokem 2017 byla AI Å¡patnÃ¡ na dlouhÃ© vÄ›ty. NeÅ¾ se dostala na konec, zapomnÄ›la zaÄÃ¡tek.
Pak Google vynalezl **Transformer**.

Tou tajnou pÅ™Ã­sadou je **"Sebe-pozornost" (Self-Attention)**.
PÅ™edstav si, Å¾e ÄteÅ¡ vÄ›tu: *"ZvÃ­Å™e nepÅ™eÅ¡lo ulici, protoÅ¾e bylo pÅ™Ã­liÅ¡ unavenÃ©."*

*   **StarÃ¡ AI:** ÄŒte zleva doprava. Zmate ji "bylo".
*   **Transformer:** PodÃ­vÃ¡ se na "bylo" a spojÃ­ si ho se "zvÃ­Å™e" (ne "ulicÃ­") dÃ­ky kontextu "unavenÃ©".

<Diagram type="transformer-architecture-simplified" />

VÄ›nuje "pozornost" vÅ¡em slovÅ¯m najednou a vÃ¡Å¾Ã­ jejich dÅ¯leÅ¾itost. Proto tak dobÅ™e chÃ¡pe kontext.

---

## ğŸ”¢ 3. NeÄte slova. ÄŒte ÄÃ­sla.

Tady je tajemstvÃ­: PoÄÃ­taÄe neumÃ­ ÄÃ­st. UmÃ­ jen poÄÃ­tat.
NeÅ¾ LLM uvidÃ­ tvÅ¯j prompt, rozsekÃ¡ ho na malÃ© kousky zvanÃ© **Tokeny**.

PÅ™edstav si tokeny jako **KostiÄky Lega**.
*   ğŸ **Jablko** = 1 KostiÄka
*   ğŸ§± **Ing** (pÅ™Ã­pona) = 1 KostiÄka
*   â¬œ **Mezera** = 1 KostiÄka

Zhruba platÃ­: **1 000 tokenÅ¯ â‰ˆ 750 slov**.
AI pÅ™evede tyto tokeny na ÄÃ­sla (napÅ™. `18342`), provede na nich matematickÃ© operace a vÃ½sledek pÅ™evede zpÄ›t na slova.

<Diagram type="tokenization-viz" />

---

## ğŸ”¬ Lab 1: Pohled TokenizÃ©ru

Je Äas spatÅ™it Matrix. DonuÅ¥me AI odhalit, jak vidÃ­ jazyk.

**CÃ­l:** Vizualizovat tokeny.

**Prompt:**
```text
PÅ™epiÅ¡ prosÃ­m slovo "NejneobhospodaÅ™ovÃ¡vatelnÄ›jÅ¡Ã­mi" ale vloÅ¾ svislou ÄÃ¡ru "|" mezi kaÅ¾dÃ½ token, kterÃ½ bys vnÃ­mal.
VysvÄ›tli, proÄ jsi to tak rozdÄ›lil.
```

**AnalÃ½za:**
*   Nebude to jedno slovo. Bude to `Nejne|obhos|podaÅ™|...`.
*   To dokazuje, Å¾e AI vidÃ­ shluky znakÅ¯, ne celÃ¡ slova. Proto mÃ¡ AI nÄ›kdy problÃ©my s pravopisem nebo rÃ½movÃ¡nÃ­mâ€”nevidÃ­ pÃ­smena!

<LabComplete labId="lab-tokenizer-view" />

---

## ğŸ§  4. KontextovÃ© okno (KrÃ¡tkodobÃ¡ pamÄ›Å¥)

UÅ¾ jsi nÄ›kdy mluvil s ChatGPT tak dlouho, Å¾e zapomnÄ›la, co jsi Å™Ã­kal na zaÄÃ¡tku?
To je kvÅ¯li **KontextovÃ©mu oknu**.

PÅ™edstav si Jediho odrÃ¡Å¾ejÃ­cÃ­ho stÅ™ely z blasterÅ¯. MÅ¯Å¾e se soustÅ™edit jen na urÄitÃ½ poÄet najednou. Pokud jich pÅ™ijde pÅ™Ã­liÅ¡ mnoho, pustÃ­ ty dÅ™Ã­vÄ›jÅ¡Ã­, aby se soustÅ™edil na novÃ©.

<Diagram type="context-window" />

*   **Vstup:** VÅ¡e, co napÃ­Å¡eÅ¡ + vÅ¡e, co AI zatÃ­m odpovÄ›dÄ›la.
*   **Limit:** KaÅ¾dÃ½ model mÃ¡ maximÃ¡lnÃ­ limit (napÅ™. 128k tokenÅ¯).
*   **PÅ™eteÄenÃ­:** Pokud pÅ™ekroÄÃ­Å¡ limit, AI "zapomene" nejstarÅ¡Ã­ ÄÃ¡st konverzace (FIFO: PrvnÃ­ dovnitÅ™, prvnÃ­ ven).

---

## ğŸŒ¡ï¸ 5. Teplota: Od Droida k BÃ¡snÃ­kovi

Jak udÄ›lÃ¡me z matematickÃ©ho stroje kreativce? UpravÃ­me **Teplotu**.
Tento parametr Å™Ã­dÃ­, jak "riskantnÃ­" je AI pÅ™i vÃ½bÄ›ru dalÅ¡Ã­ho tokenu.

<Diagram type="temperature-scale" />

*   â„ï¸ **Teplota 0.0 (SithskÃ¡ logika):** VÅ¾dy vybere nejpravdÄ›podobnÄ›jÅ¡Ã­ slovo. PÅ™esnÃ©, chladnÃ©, robotickÃ©. (KÃ³dovÃ¡nÃ­, Matematika).
*   ğŸ”¥ **Teplota 1.0 (Intuice JediÅ¯):** Riskuje. VybÃ­rÃ¡ mÃ©nÄ› pravdÄ›podobnÃ¡ slova. KreativnÃ­, chaotickÃ©. (Poezie, NÃ¡pady).

---

## ğŸ”¬ Lab 2: Simulace Teploty

VÄ›tÅ¡ina chatovacÃ­ch aplikacÃ­ nemÃ¡ posuvnÃ­k, ale mÅ¯Å¾eme to simulovat promptem.

**CÃ­l:** VidÄ›t rozdÃ­l mezi Logikou (Teplota 0) a Chaosem (Teplota 1).

**Prompt:**
```text
Ãškol: PopiÅ¡ zÃ¡pad slunce.
Verze 1 (Teplota 0): BuÄ extrÃ©mnÄ› struÄnÃ½, faktickÃ½ a vÄ›deckÃ½. Å½Ã¡dnÃ© emoce.
Verze 2 (Teplota 1): BuÄ abstraktnÃ­, poetickÃ½, chaotickÃ½ a metaforickÃ½. PouÅ¾Ã­vej vzÃ¡cnÃ¡ slova.
```

**AnalÃ½za:**
*   **Verze 1:** "Slunce kleslo pod obzor, zpÅ¯sobujÃ­c RayleighÅ¯v rozptyl..."
*   **Verze 2:** "KrvÃ¡cejÃ­cÃ­ Å¾loutek se roztÅ™Ã­Å¡til o zubatÃ© tesÃ¡ky hor..."

<LabComplete labId="lab-simulating-temperature" />

---

## ğŸ­ 6. Jak se rodÃ­ model

LLM se jen tak neobjevÃ­. Je ukovÃ¡n ve dvou ohnÃ­ch.

<Diagram type="training-pipeline" />

1.  **PÅ™edtrÃ©novÃ¡nÃ­ (ZÃ¡kladnÃ­ model):** ÄŒte internet. Je divokÃ½ a nepÅ™edvÃ­datelnÃ½. Chce jen dokonÄovat vÄ›ty.
2.  **DoladÄ›nÃ­ (ChatovacÃ­ model):** LidÃ© ho uÄÃ­ bÃ½t nÃ¡pomocnÃ½m. Tak se ze surovÃ©ho GPT-4 stÃ¡vÃ¡ ChatGPT.

---

## ğŸ† 7. ZÃ¡vÄ›reÄnÃ¡ zprÃ¡va z mise

PodÃ­val ses pod kapotu. NenÃ­ to magie. Je to matematika.

<ConceptCard title="Holocron: Architektura LLM" icon="ğŸ’¾">

### ğŸ”‘ KlÃ­ÄovÃ© komponenty
*   **Tokeny:** Atomy jazyka. (1000 tokenÅ¯ â‰ˆ 750 slov).
*   **KontextovÃ© okno:** OmezenÃ¡ vyrovnÃ¡vacÃ­ pamÄ›Å¥.
*   **Teplota:** OvladaÄ kreativity (0 = Logika, 1 = Chaos).
*   **Halucinace:** KdyÅ¾ motor pÅ™edpovÄ›dÃ­ sebevÄ›domÄ› hÃ¡dÃ¡ Å¡patnÃ¡ fakta.

### ğŸ›¡ï¸ Moudrost JediÅ¯
*   **DalÅ¡Ã­ token:** AI vÅ¾dy jen hÃ¡dÃ¡, co pÅ™ijde dÃ¡l.
*   **DÅ¯vÄ›ra:** OvÄ›Å™uj fakta. DÅ¯vÄ›Å™uj kreativitÄ›.

</ConceptCard>

**PÅ™Ã­Å¡tÃ­ lekce:** TeÄ znÃ¡Å¡ teorii. Je Äas mluvit jazykem. PÅ™iprav se na **Prompt Engineering**.
