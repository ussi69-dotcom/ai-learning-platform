[
  {
    "question": "What is an 'AI Hallucination'?",
    "option_a": "When the AI refuses to answer.",
    "option_b": "When the AI confidently generates a factually incorrect answer.",
    "option_c": "When the AI becomes sentient.",
    "option_d": "When the AI generates an image.",
    "correct_answer": "B",
    "explanation": "A hallucination is when an LLM generates false information with high confidence because it is predicting probable words, not retrieving facts.",
    "order": 1
  },
  {
    "question": "Why do AI models have 'Bias'?",
    "option_a": "Because the developers programmed them to be mean.",
    "option_b": "Because they are trained on internet data, which contains human stereotypes and prejudices.",
    "option_c": "Because they hate humans.",
    "option_d": "They don't have bias.",
    "correct_answer": "B",
    "explanation": "AI models are mirrors of their training data. If the internet has bias (e.g., gender stereotypes), the AI learns and repeats those patterns.",
    "order": 2
  },
  {
    "question": "What is a 'Knowledge Cutoff'?",
    "option_a": "The AI shuts down at night.",
    "option_b": "The date when the AI's training data ends; it doesn't know events after this date.",
    "option_c": "The limit of how smart the AI is.",
    "option_d": "A safety switch.",
    "correct_answer": "B",
    "explanation": "Training an LLM takes months and stops at a certain date. Without web access (RAG), the AI literally does not know about events that happened after that date.",
    "order": 3
  },
  {
    "question": "What is the best defense against deepfakes (AI-generated fake voices/videos)?",
    "option_a": "Trust everything you see.",
    "option_b": "Skepticism and verification (e.g., family code words, checking sources).",
    "option_c": "Delete your social media.",
    "option_d": "Ask the AI if it's fake.",
    "correct_answer": "B",
    "explanation": "In the age of AI, seeing is no longer believing. You must verify sources and use security measures like code words for family emergencies.",
    "order": 4
  },
  {
    "question": "How can you reduce hallucinations in your prompts?",
    "option_a": "Ask the AI to be creative.",
    "option_b": "Tell the AI: 'If you don't know, say you don't know.'",
    "option_c": "Use negative constraints.",
    "option_d": "Type in all caps.",
    "correct_answer": "B",
    "explanation": "Giving the AI permission to admit ignorance reduces the chance it will invent a plausible-sounding lie to satisfy your request.",
    "order": 5
  }
]
