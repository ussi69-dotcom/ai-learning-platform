{
  "lesson": {
    "course_id": "ai-basics-beginner",
    "lesson_number": 5,
    "lesson_path": "content/courses/ai-basics-beginner/lessons/05-the-dark-side/",
    "title": "The Dark Side of AI: Hallucinations & Bias",
    "target_level": "beginner",
    "estimated_minutes": 25,
    "labs_count": 4,
    "focus_topics": ["hallucinations", "bias", "safety", "knowledge_cutoff", "rag"],
    "existing_diagrams": ["alignment-misalignment", "bias-in-data"],
    "last_updated": "2025-12-21"
  },
  "learning_outcomes": [
    "Explain, in plain language, why LLMs can hallucinate (next-token prediction) and why fluent answers can still be wrong.",
    "Identify common hallucination failure modes (fact fabrication, code hallucination, and source/citation fabrication) and apply an output verification workflow.",
    "Run a simple bias check by varying demographic attributes in prompts and comparing the model's assumptions and tone for stereotyping or unfairness.",
    "Use a retrieval-grounded workflow (RAG, search, or provided documents) to answer time-sensitive questions, and verify citations by opening and cross-checking sources.",
    "Decide when not to use AI (high-stakes contexts) and apply a basic safety checklist (stakes, fact check, bias check, time check)."
  ],
  "prerequisites": {
    "required_lessons_01_to_04": [
      {
        "lesson_id": "01-what-is-ai",
        "title": "What is Artificial Intelligence?",
        "what_students_should_already_know": [
          "High-level definition of AI vs ML vs deep learning",
          "That modern AI behavior comes from training data + optimization, not magic"
        ]
      },
      {
        "lesson_id": "02-how-does-ai-learn",
        "title": "How Does AI Learn?",
        "what_students_should_already_know": [
          "Concept of training from examples (data → pattern learning)",
          "That models optimize for a loss/goal and can inherit problems from data"
        ]
      },
      {
        "lesson_id": "03-llms-explained",
        "title": "The Mind of the Machine: LLMs",
        "what_students_should_already_know": [
          "LLMs generate text by predicting the next token",
          "Why confidence/fluency is not the same as correctness"
        ]
      },
      {
        "lesson_id": "04-your-first-prompt",
        "title": "Talking to AI - Your First Prompt",
        "what_students_should_already_know": [
          "How to write clearer prompts (context + instruction + format)",
          "How to ask for citations/sources and constrain outputs"
        ]
      }
    ]
  },
  "must_be_true_facts": [
    {
      "id": "mata-avianca-fake-citations-2023",
      "fact": "In Mata v. Avianca (S.D.N.Y., 2023), lawyers submitted a filing with citations to non-existent cases generated by ChatGPT; the court imposed sanctions including a $5,000 penalty and required notification letters to the client and judges whose names were used in the fake opinions.",
      "sources": [
        {
          "type": "court_order",
          "title": "Opinion and Order on Sanctions (ECF 54) — Mata v. Avianca, Inc.",
          "citation": "Mata v. Avianca, Inc., No. 1:22-cv-01461 (PKC), ECF 54 (S.D.N.Y. Jun. 22, 2023).",
          "url": "https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2022cv01461/575368/54/"
        },
        {
          "type": "docket",
          "title": "Case docket — Mata v. Avianca, Inc.",
          "citation": "Mata v. Avianca, Inc., No. 1:22-cv-01461 (PKC) (S.D.N.Y.) (CourtListener docket).",
          "url": "https://www.courtlistener.com/docket/63107798/mata-v-avianca-inc/"
        }
      ]
    },
    {
      "id": "stochastic-parrots-bender-2021",
      "fact": "The term 'stochastic parrots' (Bender et al., 2021) is used to describe large language models that generate fluent text by learning statistical patterns in data, without grounded understanding; the paper argues these systems can amplify bias and cause harm when deployed uncritically.",
      "sources": [
        {
          "type": "paper",
          "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?",
          "citation": "Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? Proceedings of the 2021 ACM FAccT. https://doi.org/10.1145/3442188.3445922",
          "url": "https://dl.acm.org/doi/10.1145/3442188.3445922"
        }
      ]
    },
    {
      "id": "knowledge-cutoff-current-models-dec-2025",
      "fact": "As of Dec 2025, vendor documentation still lists a training-data knowledge cutoff for 'current' models (example: GPT-5 and o3), meaning they can be out of date on recent events unless they use retrieval tools.",
      "details": {
        "models_and_cutoffs": [
          {
            "model": "GPT-5",
            "knowledge_cutoff": "Sep 30, 2024",
            "source_url": "https://platform.openai.com/docs/models/gpt-5"
          },
          {
            "model": "o3",
            "knowledge_cutoff": "Jun 01, 2024",
            "source_url": "https://platform.openai.com/docs/models/o3"
          }
        ]
      },
      "sources": [
        {
          "type": "vendor_docs",
          "title": "GPT-5 model documentation (knowledge cutoff)",
          "citation": "OpenAI Platform Docs — GPT-5 (knowledge cutoff listed on model page).",
          "url": "https://platform.openai.com/docs/models/gpt-5"
        },
        {
          "type": "vendor_docs",
          "title": "o3 model documentation (knowledge cutoff)",
          "citation": "OpenAI Platform Docs — o3 (knowledge cutoff listed on model page).",
          "url": "https://platform.openai.com/docs/models/o3"
        }
      ]
    },
    {
      "id": "rag-mitigates-knowledge-cutoff",
      "fact": "Retrieval-Augmented Generation (RAG) mitigates knowledge cutoff by retrieving relevant documents at query time and conditioning generation on those retrieved sources, improving factual grounding and enabling updates without full retraining.",
      "sources": [
        {
          "type": "paper",
          "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
          "citation": "Lewis, P. et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020. arXiv:2005.11401. https://doi.org/10.48550/arXiv.2005.11401",
          "url": "https://arxiv.org/abs/2005.11401"
        }
      ]
    }
  ],
  "dont_claim": [
    "Don't use outdated model names (e.g., GPT-4, GPT-4o) when giving 'current model' examples; use GPT-5 and o3.",
    "Don't say the AI 'knows', 'understands', or 'believes' things; describe it as predicting likely text based on patterns.",
    "Don't overstate AI consciousness, intention, or human-like understanding; avoid implying sentience.",
    "Don't imply hallucinations only happen to 'bad models' or only in niche topics; they can occur across domains and formats.",
    "Don't claim RAG guarantees truth; retrieved sources can be wrong or irrelevant, and citations must still be verified."
  ],
  "rubric": {
    "hook_effectiveness_min": 8,
    "concept_clarity_min": 8,
    "lab_quality_min": 8,
    "visual_anchors_min": 8,
    "progressive_difficulty_min": 8,
    "edutainment_factor_min": 8,
    "masterpiece_total_min": 59,
    "masterpiece_total_max": 60,
    "rules": [
      "Any category score below 8/10 fails the MASTERPIECE gate, even if the total meets the threshold.",
      "MASTERPIECE requires total ≥59/60."
    ]
  }
}
