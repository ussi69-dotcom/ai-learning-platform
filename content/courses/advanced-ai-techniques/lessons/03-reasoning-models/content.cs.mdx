# Reasoning modely: KdyÅ¾ AI skuteÄnÄ› pÅ™emÃ½Å¡lÃ­ ğŸ§ 

<Callout type="info">
**Mise:** Osvojte si umÄ›nÃ­ AI â€SystÃ©mu 2". NauÄte se, kdy a jak nasadit modely, kterÃ© nejen pÅ™edpovÃ­dajÃ­, ale skuteÄnÄ› uvaÅ¾ujÃ­.

â³ **ÄŒas ÄtenÃ­:** 35 min | ğŸ§ª **[2] Laby souÄÃ¡stÃ­**
</Callout>

<VideoSwitcher alternatives={[
  {"id":"QB3l9sFV2Kk","title":"GPT 5.2 - First AI I'd Give My Work To"},
  {"id":"g52sAfxjX4k","title":"How OpenAI's 'Thinking' Model Actually Works"}
]} />

Co kdybych vÃ¡m Å™ekl, Å¾e 99 % AI, se kterou interagujete, je geniÃ¡lnÃ­ podvodnÃ­k? OslnivÄ› rychlÃ½ papouÅ¡ek s fotografickou pamÄ›tÃ­, schopnÃ½ pÅ™edpovÃ­dat dalÅ¡Ã­ slovo s nadlidskou pÅ™esnostÃ­, ale zÃ¡sadnÄ› neschopnÃ½ *pÅ™emÃ½Å¡let*. Je to stroj na instinktivnÃ­ reakce.

Dnes se to mÄ›nÃ­. Vstupujeme do dalÅ¡Ã­ evoluce umÄ›lÃ© inteligence. Jdeme za hranice predikce do sfÃ©ry uvaÅ¾ovÃ¡nÃ­. VÃ­tejte ve svÄ›tÄ› Reasoning modelÅ¯.

---

## Dva mozky AI: SystÃ©m 1 vs. SystÃ©m 2

Psycholog Daniel Kahneman ve svÃ© prÅ¯lomovÃ© knize â€MyÅ¡lenÃ­, rychlÃ© a pomalÃ©" popsal dva zpÅ¯soby lidskÃ©ho myÅ¡lenÃ­. Tento rÃ¡mec je tou nejlepÅ¡Ã­ analogiÃ­ pro pochopenÃ­ seismickÃ©ho posunu, kterÃ½ se prÃ¡vÄ› teÄ v AI dÄ›je.

*   **SystÃ©m 1 (IntuitivnÃ­ pilot):** To je vaÅ¡e instinktivnÃ­ reakce. Je rychlÃ¡, automatickÃ¡ a bez nÃ¡mahy. DÃ­ky nÃ­ vÃ­te, Å¾e 2+2=4, poznÃ¡te tvÃ¡Å™ pÅ™Ã­tele nebo zÃ­skÃ¡te â€pocit" z konverzace. VÄ›tÅ¡ina LLM, od GPT-5 mini po Claude Sonnet 4, funguje primÃ¡rnÄ› jako motory SystÃ©mu 1. Jsou mistry v rozpoznÃ¡vÃ¡nÃ­ vzorcÅ¯ a okamÅ¾itÃ© reakci.

*   **SystÃ©m 2 (UvaÅ¾ujÃ­cÃ­ myslitel):** To je vaÅ¡e vÄ›domÃ©, uvaÅ¾ujÃ­cÃ­ jÃ¡. Je pomalÃ©, nÃ¡roÄnÃ© a analytickÃ©. Je to ÄÃ¡st vaÅ¡eho mozku, kterÃ¡ Å™eÅ¡Ã­ sloÅ¾itÃ½ matematickÃ½ problÃ©m, plÃ¡nuje vÃ­cekrokovÃ½ projekt nebo zvaÅ¾uje pro a proti zÃ¡sadnÃ­ho Å¾ivotnÃ­ho rozhodnutÃ­. Toto je domÃ©na skuteÄnÃ½ch Reasoning modelÅ¯.

<Diagram type="system1-vs-system2" />

Toto nenÃ­ jen metafora; je to architektonickÃ¡ realita. Modely jako `o3` a `o3-pro` od OpenAI a frontier GPT-5 reasoning varianty jsou postaveny jinak. NejenÅ¾e â€vyplivnou" nejpravdÄ›podobnÄ›jÅ¡Ã­ dalÅ¡Ã­ token. Dostanou â€kognitivnÃ­ rozpoÄet" â€“ Äas a vÃ½poÄetnÃ­ zdroje â€“ na *pÅ™emÃ½Å¡lenÃ­* pÅ™ed odpovÄ›dÃ­.

| Vlastnost | KonvenÄnÃ­ LLM (SystÃ©m 1) | Reasoning Model (SystÃ©m 2) |
| :--- | :--- | :--- |
| **PrimÃ¡rnÃ­ cÃ­l** | PÅ™edpovÄ›dÄ›t dalÅ¡Ã­ nejpravdÄ›podobnÄ›jÅ¡Ã­ slovo | DojÃ­t ke sprÃ¡vnÃ©mu, odÅ¯vodnÄ›nÃ©mu zÃ¡vÄ›ru |
| **Doba odezvy** | Milisekundy aÅ¾ sekundy | Sekundy aÅ¾ minuty |
| **Proces** | JednoprÅ¯chodovÃ¡, intuitivnÃ­ generace | VÃ­cekrokovÃ©, iterativnÃ­ uvaÅ¾ovÃ¡nÃ­ |
| **NejlepÅ¡Ã­ pro** | KreativnÃ­ psanÃ­, shrnutÃ­, chat | LogickÃ© hÃ¡danky, vÄ›deckÃ© problÃ©my, generovÃ¡nÃ­ kÃ³du |
| **Analogie** | GeniÃ¡lnÃ­ improvizÃ¡tor | Velmistr v Å¡achu |

---

## Prompting vs. Pondering: CoT vs. Extended Thinking

LÃ©ta jsme pouÅ¾Ã­vali chytrÃ½ trik, jak pÅ™imÄ›t modely SystÃ©mu 1, aby se *chovaly*, jako by umÄ›ly uvaÅ¾ovat: **Chain-of-Thought (CoT) prompting**. TÃ­m, Å¾e modelu Å™ekneme, aby â€pÅ™emÃ½Å¡lel krok za krokem", nutÃ­me ho externalizovat svÅ¯j proces a mÄ›nÃ­me sloÅ¾itÃ½ problÃ©m v sÃ©rii jednoduÅ¡Å¡Ã­ch predikcÃ­ dalÅ¡Ã­ho slova. Je to geniÃ¡lnÃ­ hack.

Ale poÅ™Ã¡d je to jen hack.

**Extended Thinking**, nativnÃ­ schopnost reasoning modelu, je jinÃ¡. NemusÃ­te ho drÅ¾et za ruku. Model se *sÃ¡m* rozhodne, kdy zpomalit a pÅ™emÃ½Å¡let.

<Diagram type="cot-vs-extended-thinking" />

<ConceptCard title="Chain-of-Thought: PromptovacÃ­ trik" icon="ğŸª„">

CoT je **technika prompt engineeringu**, kterÃ¡ pÅ™imÄ›je model SystÃ©mu 1 simulovat proces uvaÅ¾ovÃ¡nÃ­. Je efektivnÃ­, ale kÅ™ehkÃ¡. Pokud model udÄ›lÃ¡ chybu v kroku 1, celÃ½ â€Å™etÄ›zec" je naruÅ¡en. Je to jako nutit sprintera bÄ›Å¾et maraton â€“ moÅ¾nÃ¡ dobÄ›hne, ale nenÃ­ na to stavÄ›nÃ½.

</ConceptCard>

<Callout type="warning">
**Cena za poznÃ¡nÃ­**

Reasoning modely nejsou nÃ¡hradou za standardnÃ­ LLM. Jsou to specialistÃ©. OÄekÃ¡vejte, Å¾e budou **10-100x pomalejÅ¡Ã­** a vÃ½raznÄ› draÅ¾Å¡Ã­. Jejich nasazenÃ­ je jako povolat mistra Jedi â€“ udÄ›lÃ¡te to jen tehdy, kdyÅ¾ je v sÃ¡zce hodnÄ› a jednoduchÃ¡ stÅ™elba z blasteru nestaÄÃ­.
</Callout>

---

## ğŸ”¬ Lab 1: Rukavice logickÃ½ch hÃ¡danek

KlasickÃ½ model SystÃ©mu 1 Äasto u tohoto typu logickÃ© hÃ¡danky selÅ¾e, protoÅ¾e se zmate ve vztazÃ­ch a negativnÃ­ch omezenÃ­ch. PÅ™edpovÃ­dÃ¡ vÄ›rohodnÄ› znÄ›jÃ­cÃ­ spojenÃ­, mÃ­sto aby logicky odvodil jedinou sprÃ¡vnou odpovÄ›Ä.

**CÃ­l:** PouÅ¾ijte logickou hÃ¡danku k odhalenÃ­ rozdÃ­lu mezi modelem, kterÃ½ pÅ™edpovÃ­dÃ¡, a modelem, kterÃ½ uvaÅ¾uje.

**Prompt:**
ZkopÃ­rujte toto do standardnÃ­ho modelu (napÅ™. GPT-5 mini) a do Å¡piÄkovÃ©ho reasoning modelu, pokud k nÄ›mu mÃ¡te pÅ™Ã­stup (napÅ™. Claude Opus 4 nebo OpenAI o3-pro):

```text
V mÃ­stnosti je pÄ›t lidÃ­: Alice, Bob, Charlie, David a Eve.
KaÅ¾dÃ¡ osoba mÃ¡ jedineÄnou oblÃ­benou barvu: Äervenou, zelenou, modrou, Å¾lutou nebo fialovou.
StojÃ­ v Å™adÄ›.

1. Osoba, kterÃ¡ mÃ¡ rÃ¡da Å¾lutou, je o dvÄ› mÃ­sta nalevo od Boba.
2. Alice je na jednom z koncÅ¯ Å™ady.
3. Osoba, kterÃ¡ mÃ¡ rÃ¡da zelenou, je hned napravo od osoby, kterÃ¡ mÃ¡ rÃ¡da Äervenou.
4. Charlie, kterÃ½ nemÃ¡ rÃ¡d Å¾lutou, je nÄ›kde napravo od Alice.
5. Osoba na tÅ™etÃ­ pozici miluje fialovou.
6. David je pÅ™Ã­mo mezi osobou, kterÃ¡ mÃ¡ rÃ¡da modrou, a osobou, kterÃ¡ mÃ¡ rÃ¡da Å¾lutou.

Na zÃ¡kladÄ› *pouze* tÄ›chto faktÅ¯, kdo mÃ¡ rÃ¡d jakou barvu a jakÃ© je koneÄnÃ© poÅ™adÃ­ lidÃ­ v Å™adÄ›? UveÄte pouze koneÄnou odpovÄ›Ä jako seznam jmen a jejich barev zleva doprava.
```

**OÄekÃ¡vanÃ½ vÃ½stup:**
Reasoning model sprÃ¡vnÄ› integruje vÅ¡echna omezenÃ­. StandardnÃ­ model mÅ¯Å¾e udÄ›lat chybu, Äasto u pravidla Ä. 4 nebo Ä. 6.

**SprÃ¡vnÃ¡ odpovÄ›Ä:** `Alice (modrÃ¡), David (Å¾lutÃ¡), Eve (fialovÃ¡), Bob (ÄervenÃ¡), Charlie (zelenÃ¡)`

**ğŸ’¡ Aha moment:** â€StandardnÃ­ model udÄ›lÃ¡ â€šdobrÃ½ odhad', kterÃ½ poruÅ¡uje pravidlo. Reasoning model si vytvoÅ™Ã­ mentÃ¡lnÃ­ model omezenÃ­ a najde *jedinÃ©* Å™eÅ¡enÃ­, kterÃ© vyhovuje."

<LabComplete labId="lab-reasoning-1" />

---

## NovÃ­ titÃ¡ni: Pohled na Å¡piÄku

Hranice AI je nynÃ­ bitvou o sÃ­lu uvaÅ¾ovÃ¡nÃ­. ZatÃ­mco specifikace jsou promÄ›nlivÃ© a marketing bujÃ­, objevuje se novÃ¡ tÅ™Ã­da â€pÅ™emÃ½Å¡lejÃ­cÃ­ch" modelÅ¯.

| Model | SÃ­la | Slabina | Jedi analogie |
| :--- | :--- | :--- | :--- |
| **GPT-5** | NepÅ™ekonatelnÃ¡ logickÃ¡ konzistence a komplexnÃ­ kÃ³d | NejpomalejÅ¡Ã­; nejvyÅ¡Å¡Ã­ nÃ¡klady; â€pÅ™emÃ½Å¡lÃ­ pÅ™Ã­liÅ¡" o jednoduchÃ½ch problÃ©mech | Mace Windu (PÅ™esnÃ½, mocnÃ½ a nekompromisnÃ­) |
| **Claude Opus 4** | NuancovanÃ© etickÃ© a kreativnÃ­ uvaÅ¾ovÃ¡nÃ­ | MÅ¯Å¾e bÃ½t rozvlÃ¡ÄnÃ½; potÃ½kÃ¡ se s vysoce abstraktnÃ­ matematikou | Obi-Wan Kenobi (MoudrÃ½, spolehlivÃ½, mistr obrany) |
| **OpenAI o3-pro** | HloubkovÃ© uvaÅ¾ovÃ¡nÃ­ + silnÃ½ tool use | PomalejÅ¡Ã­; drahÃ© pro dlouhÃ© Ãºlohy | Qui-Gon Jinn (NekonvenÄnÃ­, rychlÃ½, nÃ¡sleduje Å½ivoucÃ­ SÃ­lu) |
| **DeepSeek R1** | Open-source; vynikÃ¡ ve vÃ­cekrokovÃ©m kÃ³du | MÃ©nÄ› obecnÃ½ch znalostÃ­; vyÅ¾aduje vÃ­ce fine-tuningu | ZakÃ¡zkovÄ› postavenÃ½ Jedi Starfighter (VÃ½konnÃ½, ale potÅ™ebuje zruÄnÃ©ho pilota) |

<Diagram type="reasoning-models-radar" />

---

<ConceptCard title="Extended Thinking: NativnÃ­ schopnost" icon="âš™ï¸">

Toto je **architektonickÃ¡ vlastnost**, ne prompt. Model dostane sloÅ¾itÃ½ Ãºkol a internÄ› ho rozloÅ¾Ã­, spustÃ­ simulace, vyhodnotÃ­ vÃ½sledky a zpÅ™esnÃ­ svou odpovÄ›Ä *pÅ™edtÃ­m*, neÅ¾ vÃ¡m ukÃ¡Å¾e jedinÃ© slovo. MÃ¡ â€poznÃ¡mkovÃ½ blok" nebo â€vnitÅ™nÃ­ monolog", kde provÃ¡dÃ­ svou prÃ¡ci. To je skuteÄnÃ¡ kognice SystÃ©mu 2.

</ConceptCard>

## ğŸ”¬ Lab 2: VÃ½zva se samoopravnÃ½m kÃ³dem

Zde je Ãºkol, kterÃ½ vyÅ¾aduje nejen generovÃ¡nÃ­ kÃ³du, ale plÃ¡novÃ¡nÃ­ architektury, pÅ™edvÃ­dÃ¡nÃ­ zÃ¡vislostÃ­ a opravovÃ¡nÃ­ vlastnÃ­ch chyb â€“ charakteristickÃ© znaky reasoning modelu.

**CÃ­l:** Zadat modelu vytvoÅ™enÃ­ vÃ­cesouborovÃ©ho skriptu, kterÃ½ vyÅ¾aduje mezisouborovÃ© zÃ¡vislosti, coÅ¾ ho nutÃ­ uvaÅ¾ovat o struktuÅ™e projektu.

**Prompt:**
ZkopÃ­rujte toto do svÃ©ho nejvÃ½konnÄ›jÅ¡Ã­ho dostupnÃ©ho modelu:

```text
VytvoÅ™te jednoduchÃ½ Python projekt se dvÄ›ma soubory: `main.py` a `utils.py`.

V `utils.py` vytvoÅ™te funkci s nÃ¡zvem `calculate_complexity`, kterÃ¡ jako vstup bere Å™etÄ›zec. Funkce by mÄ›la vracet skÃ³re na zÃ¡kladÄ› nÃ¡sledujÃ­cÃ­ch pravidel: 1 bod za kaÅ¾dÃ½ znak, 5 bodÅ¯ za kaÅ¾dou ÄÃ­slici a 10 bodÅ¯ za kaÅ¾dÃ© interpunkÄnÃ­ znamÃ©nko (napÅ™. ., !, ?).

V `main.py` importujte funkci `calculate_complexity` z `utils.py`. Skript by mÄ›l potÃ©:
1. Definovat seznam tÅ™Ã­ vÄ›t rÅ¯znÃ© sloÅ¾itosti.
2. ProjÃ­t seznam v cyklu.
3. Pro kaÅ¾dou vÄ›tu vytisknout vÄ›tu samotnou a jejÃ­ vypoÄÃ­tanÃ© skÃ³re sloÅ¾itosti pomocÃ­ importovanÃ© funkce.
4. Zahrnout blok `if __name__ == "__main__":` pro spuÅ¡tÄ›nÃ­ hlavnÃ­ logiky.

PoskytnÄ›te kompletnÃ­ obsah pro `utils.py` i `main.py`.
```

**OÄekÃ¡vanÃ½ vÃ½stup:**
Model by mÄ›l vyprodukovat dva odliÅ¡nÃ©, sprÃ¡vnÃ© bloky kÃ³du. MÃ©nÄ› schopnÃ½ model by se mohl pokusit dÃ¡t vÅ¡e do jednoho souboru, zapomenout na import nebo nesprÃ¡vnÄ› implementovat logiku skÃ³rovÃ¡nÃ­.

**`utils.py`:**
```python
import string

def calculate_complexity(text: str) -> int:
    score = 0
    for char in text:
        score += 1 # 1 bod za znak
        if char.isdigit():
            score += 5 # 5 bodÅ¯ za ÄÃ­slici
        elif char in string.punctuation:
            score += 10 # 10 bodÅ¯ za interpunkci
    return score
```

**`main.py`:**
```python
from utils import calculate_complexity

def run_analysis():
    sentences = [
        "Toto je jednoduchÃ¡ vÄ›ta.",
        "Tato je trochu sloÅ¾itÄ›jÅ¡Ã­, s ÄÃ­slem 1!",
        "PÃ¡ni! Je toto dosud nejsloÅ¾itÄ›jÅ¡Ã­ vÄ›ta, se 2 ÄÃ­sly a vÃ­ce znamÃ©nky!?"
    ]

    for sentence in sentences:
        score = calculate_complexity(sentence)
        print(f"VÄ›ta: '{sentence}'")
        print(f"SkÃ³re sloÅ¾itosti: {score}\n")

if __name__ == "__main__":
    run_analysis()
```

**ğŸ’¡ Aha moment:** â€AI nejenÅ¾e napsala kÃ³d; pochopila *strukturu* projektu. PlÃ¡novala dopÅ™edu, oddÄ›lila zodpovÄ›dnosti a sprÃ¡vnÄ› propojila oba soubory. Chovala se jako softwarovÃ½ architekt, nejen jako kodÃ©r."

<LabComplete labId="lab-reasoning-2" />

---

<Callout type="success">
**Rada Jedi: VÃ¡Å¡ tÃ½m pro uvaÅ¾ovÃ¡nÃ­**

PÅ™edstavte si svou sadu nÃ¡strojÅ¯ AI jako Radu Jedi. MÃ¡te svÃ© rychlÃ©, agilnÃ­ rytÃ­Å™e Jedi (GPT-5 mini, Claude Sonnet 4) pro kaÅ¾dodennÃ­ Ãºkoly. Ale pro problÃ©my ohroÅ¾ujÃ­cÃ­ galaxii â€“ sloÅ¾itÃ© finanÄnÃ­ modely, vÃ­cevrstvou prÃ¡vnÃ­ analÃ½zu, refaktorovÃ¡nÃ­ kÃ³du, na kterÃ©m zÃ¡visÃ­ osud firmy â€“ povolÃ¡te Mistry: reasoning modely. PouÅ¾itÃ­ sprÃ¡vnÃ©ho Jedi pro sprÃ¡vnou misi je cestou k moudrosti.
</Callout>

Toto je jen zaÄÃ¡tek. Propast mezi AI SystÃ©mu 1 a SystÃ©mu 2 bude definovat pÅ™Ã­Å¡tÃ­ desetiletÃ­ technologie. NauÄit se tuto propast pÅ™eklenout, vÄ›dÄ›t, kdy poÅ¾Ã¡dat o rychlou odpovÄ›Ä versus uvÃ¡Å¾enÃ½ Ãºsudek, je novou zÃ¡kladnÃ­ dovednostÃ­.

---

<ConceptCard title="Holokron: Reasoning Modely" icon="ğŸ’">

### ğŸ”‘ KlÃ­ÄovÃ© poznatky
*   **SystÃ©m 1 vs. SystÃ©m 2:** VÄ›tÅ¡ina AI je rychlÃ¡/intuitivnÃ­ (SystÃ©m 1); Reasoning modely jsou pomalÃ©/uvÃ¡Å¾livÃ© (SystÃ©m 2), coÅ¾ jim umoÅ¾Åˆuje Å™eÅ¡it problÃ©my, nejen pÅ™edpovÃ­dat text.
*   **CoT vs. Extended Thinking:** Chain-of-Thought je *promptovacÃ­ trik* k simulaci uvaÅ¾ovÃ¡nÃ­, zatÃ­mco Extended Thinking je *nativnÃ­ architektonickÃ¡ schopnost* skuteÄnÃ½ch reasoning modelÅ¯.
*   **PouÅ¾Ã­vejte s rozmyslem:** Reasoning modely jsou pomalÃ­, drazÃ­ specialistÃ©. PouÅ¾Ã­vejte je pro sloÅ¾itÃ©, vÃ­cekrokovÃ© Ãºkoly, kde je sprÃ¡vnost nezbytnÃ¡, jako jsou logickÃ© hÃ¡danky, komplexnÃ­ kÃ³d a hlubokÃ¡ analÃ½za.

</ConceptCard>
