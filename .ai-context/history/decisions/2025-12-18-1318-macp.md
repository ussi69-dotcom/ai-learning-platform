## Decision: Add Rate Limiting to /api/feedback Endpoint
**Date:** 2025-12-18
**Task ID:** 2025-12-18-1318
**Agents consulted:** GPT-5.2 (orchestrator), Gemini 3 Pro

## GPT-5.2 Assessment
**Recommendation:** CONDITIONAL
**Confidence:** 82%

Key points:
- High-leverage anti-abuse control for write-path endpoint
- Per-IP limiting can block legitimate users behind shared IPs (schools, NATs)
- Recommends: authenticated → per-user limits; unauthenticated → per-IP + per-cookie
- Need shared store (Redis) for distributed deployments

## Gemini Assessment
**Recommendation:** GO
**Confidence:** 100%

Key points:
- Standard security/reliability best practice
- `backend/app/limiter.py` already exists → low-effort implementation
- Suggests 5-10 submissions/minute per user/IP
- Add unit test for 429 response

## Consensus
- [x] Both GO → Proceed (GPT-5.2 conditional = GO with caveats)
- [ ] Both NO-GO → Stop
- [ ] Disagreement → Review artifacts, apply domain weights

## Final Decision
**GO** - Implement rate limiting on /api/feedback endpoint

## Rationale
Both agents agree on value. GPT-5.2's conditions are implementation details (key selection, threshold tuning) that can be addressed during implementation. The existing `limiter.py` infrastructure makes this low-risk.

## Implementation Plan
1. Use existing `limiter.py` infrastructure (SlowAPI)
2. Key on user_id if authenticated, IP if not
3. Start with 5/minute limit (can tune based on metrics)
4. Return 429 with clear message
5. Add test coverage

## Verify
- [ ] Rate limiter applied to /api/feedback route
- [ ] 429 response on limit exceeded
- [ ] Test in backend/tests/

## Artifacts
- Prompt: .ai-context/history/agent-runs/2025-12-18-1318/prompt.md
- GPT-5.2: .ai-context/history/agent-runs/2025-12-18-1318/gpt5.2-response.md
- Gemini: .ai-context/history/agent-runs/2025-12-18-1318/gemini-response.md
